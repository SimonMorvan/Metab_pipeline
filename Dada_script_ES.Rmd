---
title: "DADA2 pipeline - Español"
author: "Alexis Carteron & Simon Morvan"
date: "`r Sys.time()`"
output: 
  html_document:  
  
    toc: true
---

<br>


# Introducción
<br>

DADA2 es un pipeline bioinformático creado por [Callahan et al., 2016](https://www.ncbi.nlm.nih.gov/pubmed/27214047). Consiste es una serie de pasos que filtran las secuencias crudas obtenidas con la secuenciación de Illumina. El último paso es obtener la taxonomía de las secuencias que han sido filtradas para estudiar la comunidad microbiana.  

DADA2 tiene dos características principales que lo distinguen de otros pipelines comúnmente utilizados. Por un lado, procede a la modelización del error de secuenciación que se supone permite distinguir las secuencias mutantes de las erróneas. Por otro lado, a diferencia de otros pipelines como QIIME o Mothur, DADA2 no agrupa el 97% de las secuencias similares en unidades taxonómicas operativas (Operational Taxonomy Units, OTU). Sus variantes de secuencia de ampliación (Amplicon Sequence Variants, ASVs) no se agrupan si las secuencias no son 100% idénticas. Véase la figura anterior. 


Construido originalmente para secuencias del gen marcador 16S (Bacterias), lo utilizaremos con secuencias del gen marcador ITS (Hongos) procedentes de la secuenciación Illumina MiSEQ 2x300 bp paired-end. Para acelerar la ejecución de cada paso, submuestreamos aleatoriamente un conjunto de datos para conservar sólo 1000 secuencias por muestra.
Por último, *Redde Caesari quae sunt Caesaris* : este tutorial se ha inspirado en gran medida en el original [tutorial DADA2](https://benjjneb.github.io/dada2/tutorial.html).


En general, antes de iniciar este pipeline, debemos tomar algunas precauciones:

1.   Las muestras deben ser **demultiplexadas**: divididas en archivos fastq individuales por muestra.  
2.    2. Si las secuencias están emparejadas, las secuencias directa e inversa deben estar en archivos fastq distintos pero deben contener lecturas en **orden coincidente**.  
3.   Los nucleótidos que no forman parte del amplicón (cebadores y adaptadores) deben ser eliminados. También se pueden eliminar en el paso de filtrado.  
4.    La mayoría de las funciones tienen una opción de multihilo que permite un tiempo de cálculo más rápido al acceder a múltiples procesadores. Sólo hay que especificar *multithread = TRUE* para activarla. Atención, esta opción no funciona bajo Windows.
</span>

Esta figura tomada de [Hugerth y Andersson, 2017](https://www.ncbi.nlm.nih.gov/pubmed/28928718) ilustra la diferencia teórica entre OTUs y ASV. Cada color representa un clado. Las estrellas amarillas indican mutaciones, las rojas indican errores de amplificación o secuenciación. El tamaño del espacio entre las secuencias indica su agrupación.

<center>

![](Other_materials/ASV_vs_OTU.png) 

</center>

<br>

**(A) OTUs agrupadas con un 100% de identidad  
La más mínima variación en las secuencias provoca la creación de un nuevo grupo. Las secuencias mutantes y erróneas se tratan de la misma manera.  
**(B) OTUs agrupadas con un 97% de identidad  
Una agrupación más amplia permite descartar las secuencias erróneas, aunque las secuencias mutantes también se agruparán en el grupo de consenso.  
**(C) ASVs**  
En teoría, el aprendizaje de la tasa de error permite agrupar las secuencias erróneas con las secuencias de consenso. Sin embargo, las secuencias mutantes se consideran por derecho propio.

<br>

# ¡Comencemos! 
<br>

Primero cargaremos la biblioteca DADA2. Debería tener la última versión: `packageVersion('dada2')`.  
A continuación, crearemos una variable path que indique la ruta de acceso a los objetos que necesitaremos.  

```{r package, include=TRUE}
library(dada2); packageVersion("dada2")
path <- "data/ITS_sub/"
```

#### Comprobemos qué hay al final del camino... 

<center>

![](https://media.giphy.com/media/HVr4gFHYIqeti/giphy.gif)

</center>  
<br>

```{r path, include=TRUE}
list.files(path)
```
Debería ver los nombres de los archivos fastq.  

Ahora leeremos los nombres de los archivos fastq, y manipularemos su cadena variable para obtener una lista de fastqs sentido y antisentido. La función ordenar dará el mismo orden entre fastq sentido y antisentido.  


```{r sort, include=TRUE}
fnFs <- sort(list.files(path, pattern="_R1.fastq"))
fnRs <- sort(list.files(path, pattern="_R2.fastq"))
```

Como los pares de archivos fastq sentido y antisentido pertenecen a la misma muestra, crearemos una variable que extraiga el nombre de esa muestra. En este caso, suponemos que los nombres de los archivos fastq tienen un formato: SAMPLENAME_XXX.fastq.  


```{r samplenames, include=TRUE}
sample.names <- sapply(strsplit(fnFs, "_"), `[`, 1)
sample.names 
```

Ahora especificaremos la ruta de acceso a los objetos fnFs y fnRS.


```{r file.path, include=TRUE}
fnFs <- file.path(path, fnFs)
fnRs <- file.path(path, fnRs)
```


# Perfil de calidad  
<br>

Este primer paso nos permite visualizar la calidad de las secuencias gracias a la puntuación Q asociada a cada nucleótido.  


```{r quality_profile_ind, include=TRUE, cache=TRUE,fig.height=4,fig.width=5,fig.align='center'}
plotQualityProfile(fnFs[1]) # 1er echantillon sens
plotQualityProfile(fnRs[1]) # 1er echantillon anti-sens
```

En estas figuras, la mediana aparece en verde, y los cuartiles en naranja punteado.
Aquí hemos elegido visualizar la primera dirección de la muestra (fnFs[1]) y el antisentido (fnRs[1]), pero es posible visualizar varios gráficos al mismo tiempo (fnFs[x:y]) o agregarlos de la siguiente manera.  

```{r quality_profile_agg, include=TRUE, cache=TRUE,fig.height=4,fig.width=5,fig.align='center'}
plotQualityProfile(fnFs, aggregate = TRUE)
plotQualityProfile(fnRs, aggregate = TRUE)
```

El análisis de estos gráficos nos permite elegir los parámetros de filtrado y recorte para el siguiente paso.
De hecho, el índice de puntuación Q nos da información sobre la precisión de la secuenciación (véase la tabla siguiente).  

Resultado Q|Precisión
--|--
10|90 % 
20|99 %
30|99.9 %
40|99.99 %

Otra herramienta más completa para evaluar la calidad de la secuencia es [FastQC](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/).  


# Filtrado y truncamiento  
<br>

Primero crearemos una carpeta (filtered_pairedend) y objetos (filtFs y filtRs) para detener las secuencias filtradas.  


```{r filt_path, include=TRUE}
filt_path <- file.path(path, "filtered_pairedend") 
filtFs <- file.path(filt_path, paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(filt_path, paste0(sample.names, "_R_filt.fastq.gz"))
```

Proceda con la función **filterAndTrim**, su salida será almacenada en el objeto **out**.  

```{r filt_trim, include=TRUE,cache=TRUE}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, 
                     truncQ=6,
                     truncLen = c(280,280),
                     trimLeft=c(18,20),
                     maxEE=c(2,2))
                     #multithread=TRUE)
                
```
En primer lugar, la función necesita las secuencias no filtradas (fnFs y FnRs), así como los nombres de los objetos de las secuencias filtradas (filtFs y filtRs). A continuación, se pueden modificar varios parámetros según se desee:  

* truncQ: define un índice de puntuación Q mínimo. En la primera instancia de una puntuación de calidad menor o igual a truncQ, la secuencia se trunca.
* truncLen: define a qué longitud se truncarán las secuencias. Se eliminan las secuencias más cortas que la longitud.
* trimLeft: define la longitud que se corta en el lado 5' de las secuencias. Esto permite eliminar los cebadores si no se ha hecho antes.   
(Cartillas:  
ITS3_KYO2: GATGAAGAACGYAGYRAA = 18bp  
ITS4: TCCTCCGCTTATTGATATGC = 20bp)
* maxEE: define el número máximo de "errores esperados" permitidos en una lectura. Este filtro se basa en el índice de puntuación Q. Cuanto más alto sea el número, menos estricto será.

También se pueden modificar otros parámetros, que se pueden encontrar en la página de ayuda de la función: ?filterAndTrim.

<br>

#### Visualización del filtrado
```{r out, include=TRUE,cache=TRUE}
pourc <- cbind((out[,2]/out[,1])*100) # Porcentaje de secuencias filtradas / no filtradas
pourc_disc <- cbind(out, pourc) # Combina el objeto out y pourc
pourc_disc 
(mean(out[,2])/mean(out[,1]))*100 # Porcentaje medio
```
<br>

#### ¡Casi la mitad de las secuencias no pasaron nuestros parámetros de filtrado!  

<center>

![](https://78.media.tumblr.com/9ce0345eaa99f3a95ded99b0f80d6fa9/tumblr_inline_p7jaq4SoIC1t5s0wu_500.gif) 

</center>


<br>

>#### <span style="color:red">CHALLENGE</span> 
Trace el perfil de calidad de la primera muestra filtrada y compárelo con su perfil de calidad sin filtrar. Utilice la función **plotQualityProfile**.  <br>


Existen otras herramientas de filtrado como el : [Trimmomatic](http://www.usadellab.org/cms/?page=trimmomatic). 

<br>

# Aprender las tasas de error 

<br>

Este paso consiste en estimar la tasa de error de secuenciación. El modelo de error se calcula alternando la estimación de las tasas de error y la inferencia de la composición de la muestra hasta que convergen en una solución coherente. <br> 

```{r err, include=TRUE,cache=TRUE}
errF <- learnErrors(filtFs)
errR <- learnErrors(filtRs)
#multithread=TRUE
```

El número mínimo de secuencias a utilizar para el entrenamiento de la tasa de error puede especificarse con el parámetro *nreads*.  

<br>

#### Visualización de la tasa de error 

```{r viz_err, include=TRUE,cache=TRUE,warning=FALSE,fig.height=4,fig.width=5,fig.align='center'}
plotErrors(errF, nominalQ=TRUE)
plotErrors(errR, nominalQ=TRUE)
```

Se muestran las tasas de error de cada transición (A->C, A->G,...). Cada punto es una tasa de error observada para cada puntuación de calidad consensuada. La línea negra muestra el error después de la convergencia. La línea roja muestra el error bajo la definición del valor Q nominal (para la tecnología Illumina).  

<br>

# De-replicación  
<br>

En este paso, todas las secuencias idénticas se agruparán en *secuencias únicas* a las que se les asignan *abundancias*. Esto reducirá el tiempo de cálculo posterior al eliminar las comparaciones redundantes. Las secuencias desreplicadas reciben el nombre de las muestras de las que proceden.  

```{r derep, include=TRUE,cache=TRUE}
derepFs <- derepFastq(filtFs)
names(derepFs) <- sample.names

derepRs <- derepFastq(filtRs)
names(derepRs) <- sample.names
```

La ventaja de DADA2 es que mantiene un resumen de la información de calidad asociada a cada *secuencia única*. El perfil de calidad de consenso de una *secuencia única* es la media de las calidades posicionales de las lecturas desreplicadas. Estos perfiles de calidad informan al modelo de error del siguiente paso de inferencia de la muestra, lo que aumenta en gran medida la precisión de DADA2. 

<center>

![Unique sequences](https://media1.tenor.com/images/ea6d27c2da26e6011e6e71559a1579f7/tenor.gif)

</center>  

<br>



# Inferencia de muestras
<br>

```{r dada, include=TRUE,cache=TRUE,}
dadaFs <- dada(derepFs, 
               err = errF, 
               #multithread=TRUE,
               pool=TRUE)
               
               

dadaRs <- dada(derepRs, 
               err=errR,
               #multithread=TRUE,
               pool=TRUE)
               

dadaFs[[1]]
dadaRs[[1]]

#save(dadaRs, file="data/dadaRs.rdata")
#save(dadaFs, file="data/dadaFs.rdata")
```
<br>

# Fusión de secuencias emparejadas 

<br>

<center>

![¡FUSIÓN!](https://media.giphy.com/media/TbYgHMnICI1A4/giphy.gif)

</center>

<br>

El objetivo de la secuenciación por pares es fusionar las dos cadenas para aumentar nuestra confianza en su fiabilidad. La fusión también permite obtener amplicones más largos.  
La función **mergePairs** necesita que se le proporcionen los objetos calculados en los dos pasos anteriores (derep y dada). Entonces, los parámetros que podemos modificar libremente son:

* minOverlap: define el tamaño mínimo del solapamiento de las hebras sentido y antisentido para que su fusión sea exitosa. Las secuencias que no se fusionan se eliminan. <br>
* maxMismatch: define el número máximo de incompatibilidades de nucleótidos en el solapamiento. <br>
También se pueden cambiar otros parámetros, están accesibles en la página de ayuda de la función: ?mergePairs. Por ejemplo, si returnRejects = TRUE, los pares rechazados por falta de coincidencia en la región de solapamiento se mantienen en la salida.  

```{r merge, include=TRUE,cache=TRUE}
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, 
                      minOverlap = 12, 
                      maxMismatch = 0)
                      
```
<br>

#### ¡Veamos los resultados! 

```{r merge_inspect, include=TRUE,cache=TRUE}
head(mergers[[1]])
max(mergers[[1]]$nmatch) # Taille du plus grand chevauchement (overlap)
min(mergers[[1]]$nmatch) # Taille du plus petit chevauchement 
```

<br>

# Tabla de ASVs  

<br>

Finalmente tenemos nuestros ASVs que pararemos en el objeto *seqtab*.   


```{r seqtab, include=TRUE,cache=TRUE}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
seqtab[,1]
   
```

Obtenemos **`r dim(seqtab)[2]`** ASVs a partir de las **`r as.integer(colSums(out)[1])`** secuencias en bruto que teníamos al principio.  
seqtab[,1] da el número de veces que se encuentra la primera secuencia ASV en cada muestra.  

<br>

#### Inspeccionar la longitud de nuestros ASV 

<br>

```{r seqtab_length, include=TRUE,fig.height=4,fig.width=5,fig.align='center'}
hist(nchar(getSequences(seqtab)),xlab="Size", ylab="Frequency", main = "ASVs length", xlim=c(250,450), ylim=c(0,250)) 
```
<br>

# Eliminación de las quimeras
<br>
<center>

![](Other_materials/medusa.jpg)

</center>

<br>

Este paso tiene como objetivo eliminar todas las secuencias no biológicas, las muestras del array ASV se agrupan *(method="pooled")* para su identificación. Se pueden utilizar otros métodos, como el método de consenso, en el que cada muestra se comprueba *individualmente* para identificar los bímeros.  


```{r chim_remove, include=TRUE,cache=TRUE}
seqtab.nochim <- removeBimeraDenovo(seqtab, 
                                    method = "pooled", 
                                    #multithread = TRUE,
                                    verbose = TRUE) 
#save(seqtab.nochim, file="data/seqtab.nochim.rdata")
```
<br>

#### ¡Veamos los resultados! 

<br>

```{r chim_dim, include=TRUE,,fig.height=4,fig.width=5,fig.align='center'}
round((sum(seqtab.nochim)/sum(seqtab)*100),2) # Porcentaje del número total de secuencias no químicas / número total de secuencias
hist(nchar(getSequences(seqtab.nochim)),xlab="Size", ylab="Frequency", main = "Non-chimeric ASVs length", xlim=c(250,450), ylim=c(0,250)) # Longitud de las secuencias no químicas
```

Ahora podemos transformar las apariciones de ASV en presencia/ausencia. Esto nos permite cuantificar el número de ASV por muestra.  


```{r nochim_bin, include=TRUE,cache=TRUE}
seqtab.nochim.bin <- ifelse(seqtab.nochim>0,1,0) 
```
<br>

# Cuadro de seguimiento
<br>
La siguiente tabla muestra cuántas secuencias se han eliminado en cada etapa. Si el número de secuencias desciende demasiado, puede indicar un problema. Por ejemplo, si pocas secuencias superan el paso de eliminación de bímeros, esto puede indicar que todavía hay trozos de cebadores con nucleótidos ambiguos.  

```{r track, include=TRUE,cache=TRUE}
getN <- function(x) sum(getUniques(x))
track <- data.frame(Input=as.numeric(out[,1]), 
                    Filtered=as.numeric(out[,2]),
                    "Filt//In"=as.numeric(round(((out[,2]/out[,1])*100),2)),
                    Merge = as.numeric(sapply(mergers, getN)),
                    "Mer//In"=as.numeric(round(((sapply(mergers, getN)/out[,1])*100),2)),
                    Nonchim = as.numeric(rowSums(seqtab.nochim)),                       
                    "Nonchim//In"=as.numeric(round(((rowSums(seqtab.nochim)/out[,1])*100),2)),
                    ASV = as.numeric(rowSums(seqtab.nochim.bin)))
rownames(track) <- sample.names
head(track)
```

<br>

Una imagen vale más que mil palabras.  


```{r plot_track, include=TRUE,fig.height=4,fig.width=5,fig.align='center'}
library(ggplot2)
library(reshape2)

gtrack<- track[,c(1,2,4,6)]
gtrack$ID <- rownames(gtrack)

lgtrack <- melt(gtrack, id.vars="ID")
bar_track <- ggplot(lgtrack ,aes(x=ID, y=as.numeric(value), fill=variable)) +
      geom_bar(stat="identity", position = "identity") + 
      theme_classic() + # Thème
      theme(axis.ticks.length=unit(0.3,"cm")) + # Taille de taquets
      theme(axis.text.x = element_text(angle=45) , legend.title = element_blank())+ # Change l'orientation des  x labels  & supprime le titre de la légende
  scale_x_discrete(name ="Sample ID", limits=rownames(track))+ # Change le titre de l'axe x et le pas de l'axe
  scale_y_continuous(name="Abundance", breaks=seq(from = 0, to = 1000, by = 100))+ # Change le titre de l'axe y et le pas de l'axe.
  ggtitle("Track")# Titre principal
bar_track 
```
<br> 
  

# Asignación taxonómica   
<br>

Por fin vemos el final de la tubería con este importante paso de asignación taxonómica. Gracias a la implementación del método de clasificación bayesiano ingenuo, la función **assignTaxonomy** toma como entrada el conjunto de secuencias a clasificar así como un conjunto de secuencias de referencia con una taxonomía conocida. Las asignaciones taxonómicas se dan con una confianza bootstrap mínima especificada con el parámetro *minBoot*. La base de datos de referencia (UNITE) es accesible en este enlace https://unite.ut.ee/repository.php. También hay otras bases de datos [disponibles](https://benjjneb.github.io/dada2/training.html).


```{r assign_taxo, include=TRUE,cache=TRUE}
taxotab <- assignTaxonomy(seqtab.nochim,
                          refFasta = "reference_database/sh_general_release_dynamic_01.12.2017.fasta",
                          multithread=TRUE)
 
save(taxotab, file = "data/taxotab.rdata")
#load("data/taxotab.rdata")
```
<br>

#### ¡Veamos los resultados! 

```{r taxo_exam, include=TRUE,cache=TRUE}
# view(taxotab)
write.table(taxotab[1:5,], row.names = FALSE)
unique(unname(taxotab[,7])) 

```


>#### <span style="color:red">CHALLENGE</span>
 ¿Puedes encontrar el número de familias diferentes?    
 

# Nota Bene 
<br>
<center>

![](https://media0.giphy.com/media/135E47VKw6TM6A/giphy.gif)

</center>
<br>
  
* Dada2 no elimina las secuencias singleton. Sin embargo, se supone que la línea de producción no puede inferir variantes de secuencias biológicas que sólo se apoyan en una única secuencia, ya que se supone que las secuencias únicas son demasiado difíciles de diferenciar de los errores.

* DADA2 mide la diversidad de forma consistente a través de los diferentes parámetros de filtrado y tasa de error. Los [métodos OTU](https://twitter.com/bejcal/status/771010634074820608) no lo hacen. 

* Las ASVs sin asignación de especie no fueron asignadas a la misma especie en más del 50% de las asignaciones kmer bootstrap (ver [Wang et al., 2007](https://www.ncbi.nlm.nih.gov/pubmed/17586664) para más información sobre el método de clasificación bayesiano ingenuo).  
<br>

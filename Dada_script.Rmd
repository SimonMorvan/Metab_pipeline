---
title: "DADA2 pipeline"
author: "Alexis Carteron & Simon Morvan"
output: 
  html_document:
    toc: true

---
  
  
Date: `r Sys.time()`
<br>
<br>
    
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
  
# Introduction
<br>

Ce pipeline consiste en une série d'étapes permettant d'obtenir des séquences analysables pour les études de communautés microbiennes. A l'origine construit pour les séquences 16S, nous l'utiliserons avec des séquences amplifiées de gène marqueur ITS (Fungi) obtenus grâce à un séquençage en paire Illumina MiSEQ 2x300 paires de bases.   
Avant de débuter ce pipeline, il faut prendre quelques précautions:  

1.    Les échantillons doivent être **démultiplexés** chaque échantillon doit avoir son propre fichier fastq.  
2.    Les nucléotides qui ne font pas partie de l'amplicon (amorces, adaptateurs, bar-code) doivent avoir été retirées. Dans le cas contraire, ils devront être à l'étape de filtrage.  
3.    En cas de séquençage en paire, les séquences sens et anti-sens doivent être dans deux fichier fastq distincts et être **dans le même ordre** dans les deux fichiers.
4.    La plupart des fonctions présentées ont une option de multithreading qui permet d'accélerer les temps de calcul en accédant à plusieurs prorcesseurs. Il suffit d'indiquer *multithread = TRUE* pour l'activer. Attention, cette option ne marche pas sous Windows

<span style="color:darkblue">
This pipeline is designed in order to obtain analysable sequences for microbial community studies. Originally made for 16S sequences, we will use it here with amplified ITS sequences (Fungi)  generated by Illumina MiSEQ 2x300 bp paired-end sequencing.  
Before starting, we must take a few precautions:  

1.   <span style="color:darkblue"> Samples must be **demultiplexed**: split into individual per-sample fastqs  
2.   <span style="color:darkblue"> The nucleotides which are not part of the amplicon (primers, adapters, bar-code) have to be removed. They can be removed at the filtring step.  
3.    <span style="color:darkblue">If the sequences are paired-end, the forward and reverse sequences have to be in distinct fastq files but must contain reads in **matched order**.
4.    <span style="color:darkblue">Most functions have a multithreading option that allows faster computing time by accessing multiple processors. Just specify *multithread = TRUE* to enable it. Warning, this option does not work under Windows.
</span>
<br>
  
# Commençons ! / <span style="color:darkblue"> Let's start ! </span>
<br>

Nous allons tout d'abord chargé la librairie DADA2. Vous devriez avoir la denière version: 1.6.0.  
Puis nous allons créer une variable (path) indiquant le chemin qui permettra d'accéder aux objets dont nous allons avoir besoin.  

<span style="color:darkblue"> First, we're going to load the DADA2 package. You should have the latest version : 1.6.0. Then we're going to create a variable (path) indicating the path which will allow to access the objects required for this pipeline.  </span>
```{r package, include=TRUE}
library(dada2); packageVersion("dada2")
path <- "data/ITS_sub/"
```

#### Vérifions ce qu'il y a au bout du chemin... /<span style="color:darkblue"> Let's check where the path leads to.... </span>

<center>

![](https://media.giphy.com/media/HVr4gFHYIqeti/giphy.gif)

</center>  
<br>

```{r path, include=TRUE}
list.files(path)
```
Vous devriez voir les noms des fichiers fastq.  

<span style="color:darkblue"> You should see the names of the fastq files. </span>  
  
Nous allons maintenant lire les noms des fichiers fastq, et manipuler leur chaine de charactères variables pour obtenir une liste des fastq sens et antisens. La fonction sort permet d'obtenir le même ordre entre les fastq sens et antisens.  

<span style="color:darkblue"> Now, we're goign to read in the names of the fastq files, and perform some string manipulation to get lists of the forward and reverse fastq files. The sort function ensures forward/reverse reads are in the same order.</span>

```{r sort, include=TRUE}
fnFs <- sort(list.files(path, pattern="_R1.fastq"))
fnRs <- sort(list.files(path, pattern="_R2.fastq"))
```

Etant donné que les paires de fichiers fastq sens et antisens appartiennent au même échantillon, nous allons créer une variable qui extrait le nom de cet échantillon. Dans ce cas, nous partons du principe que les noms des fichiers fastq ont un format: SAMPLENAME_XXX.fastq.  

<span style="color:darkblue">Given that the forward/reverse fastq pairs belong to the same sample, we are going to extract the name and save it in a variable. In this case we assume that the filenames have this type of format: SAMPLENAME_XXX.fastq.</span>

```{r samplenames, include=TRUE}
sample.names <- sapply(strsplit(fnFs, "_"), `[`, 1)
sample.names 
```

Nous allons maintenant préciser le chemin d'accès aux objets fnFs et fnRS.
<span style="color:darkblue">Specify the full path to the fnFs and fnRs.</span>  

```{r file.path, include=TRUE}
fnFs <- file.path(path, fnFs)
fnRs <- file.path(path, fnRs)
```


Pour les plus maniaques d'entre nous, ce script permet d'ordonner les noms des échantillons.  

<span style="color:darkblue"> For the maniacs among us, this script allows to order the names of the samples.</span>  
```{r maniaque, include=TRUE}
library(gtools)
sample.names <- mixedsort(sample.names) 
fnFs <- mixedsort(fnFs)
fnRs <- mixedsort(fnRs)
sample.names
```

<center>
![](https://38.media.tumblr.com/d75b1fc1705b4ea3f53ea56a80b192ce/tumblr_mnda0xLsdD1rsdj6zo4_500.gif)
</center>
<br>

# Profile de qualité / <span style="color:darkblue">Quality profiles</span>  
<br>

Cette première étape permet de visualiser la qualité des séquences grâce au Q score associé à chaque nucléotide.  

<span style="color:darkblue"> This first step allows to visualize the sequences quality thanks to the individual Q score of each nucleotide </span>
```{r quality_profile_ind, include=TRUE, cache=TRUE,fig.height=4,fig.width=5,fig.align='center'}
plotQualityProfile(fnFs[1]) # 1st Forward sample
plotQualityProfile(fnRs[1]) # 1st Reverse sample
```

Dans ces figures, la médianne est en vert, et les quartiles en orange pointillé.
Ici, nous avons choisi de visualiser le premier échantillon sens (fnFs[1]) et antisens (fnRs[1]), mais il est possible de visualiser plusieurs graphiques en même temps (fnFs[x:y]) ou les aggréger comme ce qui suit.  

<span style="color:darkblue"> In these figures, the median is in green and the quartiles are the dotted orange lines. Here we only plotted the first forward and reverse fastq (fnFs[1] and fnRs[1]), but it is possible to plot multiple figures(fnFs[x:y]) or aggregate them as follows. </span>

```{r quality_profile_agg, include=TRUE, cache=TRUE,fig.height=4,fig.width=5,fig.align='center'}
plotQualityProfile(fnFs, aggregate = TRUE)
plotQualityProfile(fnRs, aggregate = TRUE)
```

L'analyse de ces graphiques nous permet de choisir les paramètres de filtrage et de rognage de la prochaine étape.
En effet, l'indice de Q score nous renseigne sur la précision du séquençage (voir tableau ci-dessous).  

<span style="color:darkblue"> The analysis of these figures helps to choose the filtring and trimming parameters of the next step. The Q score index gives us information on sequencing's accuracy (see table). </span>  

Q score|Precision
--|--
10|90 % 
20|99 %
30|99.9 %
40|99.99 %
<br>

# Filtrage et tronquage / <span style="color:darkblue"> Filtering and Trimming </span>  
<br>

Tout d'abord nous allons créer un dossier (filtered_pairedend) et des objets (filtFs et filtRs) pour stoquer les séquences filtrées.  

<span style="color:darkblue"> First we will create a directoy (filtered_pairedend) and  objects (filtFs and filtRs) to store the filtered sequences.</span>  

```{r filt_path, include=TRUE}
filt_path <- file.path(path, "filtered_pairedend") 
filtFs <- file.path(filt_path, paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(filt_path, paste0(sample.names, "_R_filt.fastq.gz"))
```

Procédons avec la fonction **filterAndTrim**, sa sortie sera stocké dans l'objet **out**.  

<span style="color:darkblue"> Let's procede with the **filterAndTrim** function, its output will be stored in the **out** object </span>  
```{r filt_trim, include=TRUE,cache=TRUE}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, 
                     truncQ=6,
                     truncLen = c(280,280),
                     trimLeft=c(18,20),
                     maxEE=c(2,2))
                     
                
```
En premier lieu, la fonction a besoin des séquences non filtrées (fnFs et FnRs) ainsi que les noms des objets des séquences filtrées (filtFs et filtRs). Plusieurs paramètres peuvent ensuite être modifiés à notre guise:  

*   truncQ : définit un l'indice Q score minimale. A la première instance d'un score de qualité inférieur ou égal à truncQ, la séquence est tronquée.
*   truncLen : définit à quelle longueur les séquences vont être tronquées. Les séquences plus courtes que la longueur sont éliminées.
*   trimLeft : définit la longueur que l'on coupe du côté 5' des séquences. Celà permet d'enlever les amorces si ça n'a pas été fait préalablement.   
(Amorces:  
ITS3_KYO2: 	GATGAAGAACGYAGYRAA = 18bp  
ITS4:	TCCTCCGCTTATTGATATGC = 20b)
*   maxEE : définit le nombre maximum d' "erreurs attendues" autorisées dans une lecture. Ce filtre se base sur l'indice Q score. Plus on augmente le chiffre moins on est strict.

D'autres paramètres peuvent également être modifiés, ils sont accessibles à la page d'aide de la fonction: ?filterAndTrim

<br>

<span style="color:darkblue">First, the function needs the unfiltered sequences (fnFs and FnRs) as well as the names of the objects of the filtered sequences (filtFs and filtRs). Several parameters can then be modified as we wish:

*   <span style="color:darkblue">truncQ: sets a minimum Q score. At the first instance of a quality score less than or equal to truncQ, the sequence is truncated.
*   <span style="color:darkblue">truncLen: sets the length at which the sequences will be truncated. Sequences shorter than the length are eliminated.
*   <span style="color:darkblue">trimLeft: sets the length that will be removed on the 5' side of the reads. This allows you to remove the primers if it has not been done beforehand.  
(Primers:  
ITS3_KYO2: 	GATGAAGAACGYAGYRAA = 18bp  
ITS4:	TCCTCCGCTTATTGATATGC = 20b)
*   <span style="color:darkblue">maxEE: sets the maximum number of “expected errors” allowed in a read. This filter is based on the Q index. The more the number is increased, the less strict we are. 

<span style="color:darkblue">Other settings can also be changed, they are accessible on the help page of the function : ?FilterAndTrim</span>

<br>

#### Visualisation du filtrage / <span style="color:darkblue">Filtring visualization</span>
```{r out, include=TRUE,cache=TRUE}
pourc <- cbind((out[,2]/out[,1])*100) # Percentage filtered sequence / non-filtered sequence
pourc_disc <- cbind(out, pourc) # combines out and pourc
pourc_disc 
(mean(out[,2])/mean(out[,1]))*100 # Mean percentage 
```
<br>

#### Plus de la moitié des séquences n'ont pas passé nos paramètres de filtrage!  

<center>

![](https://78.media.tumblr.com/9ce0345eaa99f3a95ded99b0f80d6fa9/tumblr_inline_p7jaq4SoIC1t5s0wu_500.gif) 

</center>

#### <span style="color:darkblue">More than half the reads haven't passed through the filtering parameters !</span>  

<br>

>#### <span style="color:red">CHALLENGE</span> 
Tracer le profil de qualité du premier échantillon une fois filtré et le comparer à son profil de qualité non-filtré. Utiliser la fonction **plotQualityProfile**.  <br>
<span style="color:darkblue">Draw the quality profile of the first sample once filtered and compare it to its unfiltered quality profile. Use the **plotQualityProfile** function. </span>
<br>

# Apprentissage des taux d'erreur / <span style="color:darkblue">Error Rates Learning</span>  
<br>

Cet étape consiste à estimer le taux d'erreur de séquençage. Son but est de permettre de différencier les séquences mutantes et les séquences érronées.Le modèle d'erreur est calculé en alternant l'estimation des taux d'erreur et l'inférence de la composition de l'échantillon jusqu'à ce qu'ils convergent vers une solution cohérente. <br> 

<span style="color:darkblue"> This step consist in estimating the error rates due to sequencing. Its purpose is to differentiate between mutant sequences and false sequences. The error model is computed by alternating estimation of the error rates and inference of sample composition until they converge on a jointly consistent solution. </span>

```{r err, include=TRUE,cache=TRUE}
errF <- learnErrors(filtFs)
errR <- learnErrors(filtRs)
```

Le nombre minimum de séquences à utiliser pour l'apprentissage des taux d'erreur peut être précisé avec le paramètre *nreads*.  

<span style="color:darkblue"> The minimum number of sequences to use for error rate learning can be specified with the *nreads* parameter.</span>

<br>

#### Visualisation du taux d'erreur / <span style="color:darkblue">Error rate visualization</span>
```{r viz_err, include=TRUE,cache=TRUE,warning=FALSE,fig.height=4,fig.width=5,fig.align='center'}
plotErrors(errF, nominalQ=TRUE)
plotErrors(errR, nominalQ=TRUE)
```

Les taux d'erreur pour chaque transition  (A->C, A->G,...) sont affichés. Chaque point est un taux d'erreur observé pour chaque score de qualité consensuel. La ligne noire montre l'erreur après convergence. La ligne rouge montre l'erreur sous la définition nominale de la valeur Q (pour la technologie Illumina).  

<span style="color:darkblue"> The error rates for each possible transition (eg. A->C, A->G, …) are shown. Points are the observed error rates for each consensus quality score. The black line shows the estimated error rates after convergence. The red line shows the error rates expected under the nominal definition of the Q-value (for Illumina technology).</span>  


# Déreplication / <span style="color:darkblue">Dereplicating</span>  
<br>

Dans cette étape, toutes les séquences identiques vont être regroupées en *séquences uniques* auxquelles sont attribuées des *abondances*. Cela va diminuer les temps de calcul subséquants en éliminant des comparaisons redondantes. Les séquences dérépliquées prennent le nom des échantillons d'où elles proviennent.  

<span style="color:darkblue">Combines all identical sequencing reads into into *unique sequences* with a corresponding *abundance*. It will reduce subsequent computation time by eliminating redundant comparisons. The dereplicated sequences take the name of the samples from which they come.</span>  

```{r derep, include=TRUE,cache=TRUE}
derepFs <- derepFastq(filtFs)
names(derepFs) <- sample.names

derepRs <- derepFastq(filtRs)
names(derepRs) <- sample.names
```

L'avantage de DADA2 réside dans la conservation d'un résumé des informations de qualité associées à chaque *séquence unique*. Le profil de qualité consensuel d'une *séquence unique* est la moyenne des qualités de position des lectures dérépliquées. Ces profils de qualité informent le modèle d'erreur de l'étape suivante d'inférence d'échantillon, ce qui augmente considérablement la précision de DADA2. 

<span style="color:darkblue">The advantage of DADA2 lies in the fact that it retains a summary of the quality information associated with each *unique sequence*. The consensus quality profile of a *unique sequence* is the average of the positional qualities from the dereplicated reads. These quality profiles inform the error model of the subsequent sample inference step, significantly increasing DADA2’s accuracy.</span>  

<center>

#### Unique sequences

![](https://media1.tenor.com/images/ea6d27c2da26e6011e6e71559a1579f7/tenor.gif?itemid=6117577)

</center>  <br>


# Inférence des échantillons / <span style="color:darkblue"> Sample Inference</span>  
<br>
```{r dada, include=TRUE,cache=TRUE,}
dadaFs <- dada(derepFs, 
               err = errF, 
               pool=TRUE,
               multithread=TRUE)

dadaRs <- dada(derepRs, 
               err=errR,
               pool=TRUE,
               multithread=TRUE)

dadaFs[[1]]
dadaRs[[1]]

#save(dadaRs, file="data/dadaRs.rdata")
#save(dadaFs, file="data/dadaFs.rdata")
```
<br>

# Fusion des séquences pairées / <span style="color:darkblue">Merging paired reads</span>  
<br>

<center>

#### <span style="color:red"> FUSION! </span>
![](https://media.giphy.com/media/TbYgHMnICI1A4/giphy.gif)
</center>


<br>
Tout l'intérêt du séquençage en paire réside dans le but de fusionner les deux brins afin d'accroitre notre confiance en leur fiabilité. La fusion permet également d'obtenir des amplicons plus long.  
La fonction **mergePairs** nécessite qu'on lui fournisse les objets calculés dans les deux étapes précédentes (derep et dada). Puis, les paramètres que nous pouvons modifiés librement sont:

*   minOverlap : définit la taille minimale du chevauchement des brins sens et anti-sens pour que leur fusion soit accéptée. Les séquences qui ne fusionnent pas sont éliminées. <br>
*   maxMismatch : définit le nombre maximal d'incompatibilité nucléotidique dans le chevauchement. <br>
D'autres paramètres peuvent également être modifiés, ils sont accessibles à la page d'aide de la fonction: ?mergePairs. Par exemple, si returnRejects = TRUE, les paires qui ont été rejetées en raison de discordances dans la région de chevauchement sont conservés dans la sortie.  

<span style="color:darkblue">The whole point of paired-end sequencing lies in the goal of merging the two strands to increase our confidence in their reliability. Merging also makes it possible to obtain longer amplicons.  
The function **mergePairs**  needs to be provided with the objects computed in the two preceding stages (derep and dada). Then, the parameters we can freely modify are:</span>

* <span style="color:darkblue"> minOverlap: sets the minimum size of the overlap of the sense and antisense strands for their merge to be accepted. Sequences that are not merged are discarded. </span> <br> 
* <span style="color:darkblue"> maxMismatch: sets the maximum number of nucleotidic incompatibilities in the overlap. </span> <br> 

<span style="color:darkblue"> Other settings can also be changed, they are accessible on the help page of the function : ?mergePairs. For example, if returnRejects = TRUE, pairs that were rejected because of mismatches in the overlap region are kept in the output.</span>

```{r merge, include=TRUE,cache=TRUE}
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, 
                      minOverlap = 12, 
                      maxMismatch = 0)
                      
```
<br>

#### Examinons les résultats! / <span style="color:darkblue"> Let's inspect the results! </span> 
<br>

```{r merge_inspect, include=TRUE,cache=TRUE}
head(mergers[[1]])
max(mergers[[1]]$nmatch) # Largest overlap 
min(mergers[[1]]$nmatch) # Smallest overlap           
```
<br>

# Tableau des ASVs / <span style="color:darkblue"> ASVs table </span>  
<br>

ASV signifie variants de séquences d'amplicons. C'est le nom donné aux OTUs de DADA2. Cependant ils sont bien différents des OTUs car ils n'ont à aucun moment été regroupés (à part les séquences identiques).  

<span style="color:darkblue">ASV stands for amplicon sequence variant. It is the name given to DADA2's OTUs. However, they are very different from OTUs because they have never been clustered together (except for identical sequences).</span>  

```{r seqtab, include=TRUE,cache=TRUE}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
seqtab[,1]
   
```

Nous obtenons 551 ASVs à partir des 81 000 séquences brutes que nous avions au début.  
seqtab[,1] renseigne le nombre de fois qu'on retrouve la séquence du premier ASV dans chaque échantillon.  

<span style="color:darkblue">We get 551 ASVs from the 81 000 raw sequences we had at the beginning. seqtab [, 1] gives the number of times the first ASV's sequence is found in each sample</span>    
<br>

#### Inspectons la longueur de nos ASVs / <span style="color:darkblue"> Let's inspect the ASVs' lengths</span>  

<br>

```{r seqtab_length, include=TRUE,fig.height=4,fig.width=5,fig.align='center'}
hist(nchar(getSequences(seqtab)),xlab="Size", ylab="Frequency", main = "ASVs length", xlim=c(250,450), ylim=c(0,250)) 
```
<br>

# Suppression des chimères / <span style="color:darkblue"> Removing chimeras </span>   
<br>
<center>

![](http://mythologie-grecque.e-monsite.com/medias/images/chime-re-tue-bellerophone.jpg)

</center>
<br>
Cette étape vise à éliminer toutes les séquences non biologiques, les échantillons du tableau des ASV sont regroupés *(method="pooled")* pour l'identification. D'autres méthodes peuvent être utilisées comme la méthode consensus où chaque échantillon est vérifié *individuellement* pour identifier les bimères.  

<span style="color:darkblue"> This step aims at removing all non-biological sequences, the samples in the ASV table are all pooled together for bimera identification. Other methods can be used like the consensus method where samples are checked *individually* for bimeras.</span>  


```{r chim_remove, include=TRUE,cache=TRUE}
seqtab.nochim <- removeBimeraDenovo(seqtab, 
                                    method = "pooled", 
                                    multithread = TRUE,
                                    verbose = TRUE) 
#save(seqtab.nochim, file="data/seqtab.nochim.rdata")
```
<br>

#### Examinons les résultats ! / <span style="color:darkblue"> Let's inspect the results !</span> 

<br>

```{r chim_dim, include=TRUE,,fig.height=4,fig.width=5,fig.align='center'}
round((sum(seqtab.nochim)/sum(seqtab)*100),2) # Percentage of the total sequence reads
hist(nchar(getSequences(seqtab.nochim)),xlab="Size", ylab="Frequency", main = "ASVs length", xlim=c(250,450), ylim=c(0,250)) # Lenght of the non-chimeric sequences
```

Nous pouvons également transformer les occurences des ASVs en présence / absence grâce au code çi-dessous. Cela permet de quantifier le nombre d'ASVs par échantillons.  

<span style="color:darkblue"> We can also transform the ASVs  occurrences in presence / absence thanks to the code below. It makes it possible to quantify the number of ASVs per sample.</span>  
```{r nochim_bin, include=TRUE,cache=TRUE}
seqtab.nochim.bin <- ifelse(seqtab.nochim>0,1,0) 
```
<br>

# Tableau de suivi / <span style="color:darkblue">Track table</span>  
<br>
Le tableau qui suit permet de voir combien de séquences ont été éliminées à chaque étape. Une chute trop grande du nombre de séquences peut indiquer un problème. Par exemple, si peu de séquences passent l'étape de la suppresion des bimères cela peu indiquer qu'il reste des bouts d'amorces avec de nucléotides ambigües.  

<span style="color:darkblue">The following table shows how many sequences were eliminated at each step. An excessive loss in the number of sequences may indicate a problem. For example, if too few sequences pass the bimera removal step, it may indicate that there are still bits of primers with ambiguous nucleotides.</span>
```{r track, include=TRUE,cache=TRUE}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, # input & filtered
               round(((out[,2]/out[,1])*100),2), # % (filtered / input) 
               sapply(mergers, getN), # Merged 
               round(((sapply(mergers, getN)/out[,1])*100),2), # % (Merged / Input)
               rowSums(seqtab.nochim),# Non-chimeric
               round(((rowSums(seqtab.nochim)/out[,1])*100),2),# % (Non-chimeric / Input)
               rowSums(seqtab.nochim.bin)) # Number of ASVs per sample 

colnames(track) <- c("Input", 
                    "Filter", 
                    "%Filt/In",
                    "Merge",
                    "%Mer/In", 
                    "Non-chim",
                    "%Non-chim/In",
                    "#ASV/sample") # Column names
rownames(track) <- sample.names # Row names
track<-as.data.frame(track)
head(track)
```
<br> 
  

# Assignation taxonomique / <span style="color:darkblue">  Taxonomy assignment </span>  
<br>

Nous voyons enfin le bout du pipeline avec cette importante étape d'assignation taxonomique. Grâce à l'implémentation de la méthode de classification naïve bayésienne, la fonction **assignTaxonomy** prend en entrée l'ensemble de séquences à classer, et un ensemble de séquences de référence avec une taxonomie connue pour émettre des assignations taxonomiques avec une confiance minimale de bootstrap spécifié avec le paramètre *minBoot*. La base de données de références (UNITE) est accessible sur ce lien https://unite.ut.ee/repository.php  

<span style="color:darkblue"> We are finally going to the end of the pipeline with this important step of taxonomic assignment. Thanks to the implementation of the naïve Bayesian classification method, the **assignTaxonomy** function takes as input all the sequences to be classified, and a set of reference sequences with known taxonomy to issue taxonomic assignments with a minimum bootstrap confidence specified with the *minBoot* parameter. The database of references (UNITE) is accessible on this link https://unite.ut.ee/repository.php </span>  





```{r assign_taxo, include=TRUE,cache=TRUE}
# taxotab <- assignTaxonomy(seqtab.nochim,
#                               refFasta = # "reference_database/sh_general_release_dynamic_01.12.2017.fasta", 
#                               minBoot = 50, #Default 50. The minimum bootstrap confidence for # assigning a taxonomic level.
#                               outputBootstraps = TRUE)    
#
```
<br>

#### Examinons les résulats ! / <span style="color:darkblue"> Let's inspect the results ! </span> 

```{r taxo_exam, include=TRUE,cache=TRUE}

# View(taxotab)
# unique(unname(taxotab$tax[,7])) # Number of unique species
# save(taxtab, file="data/taxotab.01.05.rdata")

```

Nous obtenons **546** espèces différentes.  
 <span style="color:darkblue"> We obtained **546** different species. </span>

>#### <span style="color:red">CHALLENGE</span>
 Pouvez-vous trouvez le nombre de famille différentes?    
<span style="color:darkblue"> Can you find the number of different families? </span><br>


# Nota Bene 
<br>
<center>

![](https://media.tenor.com/images/b9181fff25158e3ab1ecfead1dae4772/tenor.gif)

</center>
<br>
  
*   Dada2 ne supprime pas les séquences singleton. Cependant, le pipeline n'est pas supposé infèrer des variants de séquence biologique qui ne sont supportés que par une seule séquence - les singletons sont supposés être trop difficiles à différencier des erreurs.

*   DADA2 mesure la diversité de façon cohérente à travers les différents paramètres de filtrage et de taux d'erreur. Les [méthodes OTU](https://twitter.com/bejcal/status/771010634074820608) ne le font pas. 

*   Les ASV sans assignation d'espèces n'ont pas été assignié à la même espèce dans plus de 50% des affectations basées sur le kmer bootstrap (voir [Wang et al., 2007](https://www.ncbi.nlm.nih.gov/pubmed/17586664) pour plus d'informations sur la méthode de classification bayesienne naïve).  
<br>


*   <span style="color:darkblue"> Dada2 does not throw away singleton reads. However, it's not supposed infers biological sequence variants that are only supported by a single read - singletons are assumed too difficult to differentiate from errors. 

*    <span style="color:darkblue"> DADA2 consistently measures diversity across different filtering parameters and error rates. [OTU methods](https://twitter.com/bejcal/status/771010634074820608) do not. 

*    <span style="color:darkblue"> The ASVs with no species assignment do not match the same species in over 50% of the bootstrap replicate kmer-based assignments (see [Wang et al., 2007](https://www.ncbi.nlm.nih.gov/pubmed/17586664) for more info on the naive Bayesian classifier method).

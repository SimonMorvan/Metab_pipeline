---
title: "DADA2 pipeline"
author: "Alexis Carteron & Simon Morvan"
date: "9 mars 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Introduction

Ce pipeline consiste en une série d'étapes permettant d'obtenir des séquences analysables pour les études de communautés microbiennes. A l'origine construit pour les séquences 16S, nous l'utiliserons avec des séquences amplifiées de gène marqueur ITS (Fungi) obtenus grâce à un séquençage en paire Illumina MiSEQ 2x300 paires de bases.   
Avant de débuter ce pipeline, il faut prendre quelques précautions:<br>

1.    Les échantillons doivent être _démultiplexés_ chaque échantillon doit avoir son propre fichier fastq.  
2.    Les nucléotides qui ne font pas partie de l'amplicon (amorces, adaptateurs, bar-code) doivent avoir été retirées. Dans le cas contraire, ils devront être à l'étape de filtrage.  
3.    En cas de séquençage en paire, les séquences sens et anti-sens doivent être dans deux fichier fastq distincts et être _dans le même ordre_ dans les deux fichiers.

<span style="color:darkblue">
This pipeline is designed in order to obtain analysable sequences for microbial community studies. Originally made for 16S sequences, we will use it here with amplified ITS sequences (Fungi)  generated by Illumina MiSEQ 2x300 bp paired-end sequencing.  
Before starting, we must take a few precautions:<br>

1.    Samples must be _demultiplexed_: split into individual per-sample fastqs  
2.    The nucleotides which are not part of the amplicon (primers, adapters, bar-code) have to be removed. They can be removed at the filtring step.  
3.    If the sequences are paired-end, the forward and reverse sequences have to be in distinct fastq files but must contain reads in _matched order_.
</span>

### Commençons ! / <span style="color:darkblue"> Let's start </span>

Nous allons tout d'abord chargé la librairie DADA2. Vous devriez avoir la denière version: 1.6.0.  
Puis nous allons créer une variable indiquant le chemin qui permettra d'accéder aux objets dont nous allons avoir besoin.  
<span style="color:darkblue"> First, we're going to load the DADA2 package. You should have the latest version : 1.6.0. Then we're going to create a variable indicating the path which will allow to access the objects required for this pipeline.  </span>
```{r package, include=TRUE}
library(dada2); packageVersion("dada2")
path <- "data/ITS_sub/"
```

Vérifions ce qu'il y a au bout du chemin...  
<span style="color:darkblue"> Let's check where the path leads to... </span>
```{r path, include=TRUE}
list.files(path)
```
Normalement, vous devriez voir les noms des fichiers fastq.  
<span style="color:darkblue"> Normally you should see the names of the fastq files </span>  
  
Nous allons maintenant lire les noms des fichiers fastq, et manipuler leur chaine de charactères variables pour obtenir une liste des fastq sens et antisens. La fonction sort permet d'obtenir le même ordre entre les fastq sens et antisens.  
<span style="color:darkblue"> Now, we're goign to read in the names of the fastq files, and perform some string manipulation to get lists of the forward and reverse fastq files. The sort function ensures forward/reverse reads are in the same order.</span>

```{r sort, include=TRUE}
fnFs <- sort(list.files(path, pattern="_R1.fastq"))
fnRs <- sort(list.files(path, pattern="_R2.fastq"))
```

Etant donné que les paires de fichiers fastq sens et antisens appartiennent au même échantillon, nous allons créer une variable qui extrait le nom de cet échantillon. Dans ce cas, nous partons du principe que les noms des fichiers fastq ont un format: SAMPLENAME_XXX.fastq  
<span style="color:darkblue">Given that the forward/reverse fastq pairs belong to the same sample, we are going to extract the name and save it in a variable. In this case we assume that the filenames have this type of format: SAMPLENAME_XXX.fastq</span>

```{r samplenames, include=TRUE}
sample.names <- sapply(strsplit(fnFs, "_"), `[`, 1)
sample.names 
```


# Specify the full path to the fnFs and fnRs

```{r file.path, include=TRUE}
fnFs <- file.path(path, fnFs)
fnRs <- file.path(path, fnRs)
```


### Profile de qualité / <span style="color:darkblue">Quality profiles</span>  

Cette première étape permet de visualiser la qualité des séquences grâce au Q score associé à chaque nucléotide.  
<span style="color:darkblue"> This first step allows to visualize the sequences quality thanks to the individual Q score of each nucleotide </span>
```{r quality_profile_ind, include=TRUE, cache=TRUE,fig.height=3,fig.width=4}
plotQualityProfile(fnFs[1])
plotQualityProfile(fnRs[1]) 
```

Dans ces figures, la médianne est en vert, et les quartiles en orange pointillé.
Ici, nous avons choisi de visualiser le premier échantillon sens (fnFs[1]) et antisens (fnRs[1]), mais il est possible de visualiser plusieurs graphiques en même temps (fnFs[x:y]) ou les aggréger comme ce qui suit.  

<span style="color:darkblue"> In these figures, the median is in green and the quartiles are the dotted orange lines. Here we only plotted the first forward and reverse fastq (fnFs[1] and fnRs[1]), but it is possible to plot multiple figures(fnFs[x:y]) or aggregate them as follows. </span>

```{r quality_profile_agg, include=TRUE, cache=TRUE,fig.height=3,fig.width=4}
plotQualityProfile(fnFs, aggregate = TRUE)
plotQualityProfile(fnRs, aggregate = TRUE)
```

L'analyse de ces graphiques nous permet de choisir les paramètres de filtrage et de rognage de la prochaine étape.
En effet, l'indice de Q score nous renseigne sur la précision du séquençage (voir tableau ci-dessous).  

<span style="color:darkblue"> The analysis of these figures helps to choose the filtring and trimming parameters of the next step. The Q score index gives us information on sequencing's accuracy (see table). </span>  

Q score|Precision
--|--
10|90 % 
20|99 %
30|99.9 %
40|99.99 %

### Filtrage et tronquage / <span style="color:darkblue"> Filtering and Trimming </span>  

Tout d'abord nous allons créer un dossier (filtered_pairedend) et des objets (filtFs et filtRs) pour stoquer les séquences filtrées.  
<span style="color:darkblue"> First we will create a directoy (filtered_pairedend) and  objects (filtFs and filtRs) to store the filtered sequences.</span>  

```{r filt_path, include=TRUE}
filt_path <- file.path(path, "filtered_pairedend") 
filtFs <- file.path(filt_path, paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(filt_path, paste0(sample.names, "_R_filt.fastq.gz"))
```

Procédons avec la fonction **filterAndTrim**, sa sortie sera stocké dans l'objet **out**.  
<span style="color:darkblue"> Let's procede with the **filterAndTrim** function, its output will be stored in the **out** object </span>  
```{r filt_trim, include=TRUE,cache=TRUE}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, 
                     truncQ=6,
                     truncLen = c(280,280),
                     trimLeft=c(18,20),
                     maxEE=c(2,2))
                     
                
```
En premier lieu, la fonction a besoin des séquences non filtrées (fnFs et FnRs) ainsi que les noms des objets des séquences filtrées (filtFs et filtRs). Plusieurs paramètres peuvent ensuite être modifiés à notre guise: <br>

*   truncQ : définit un l'indice Q score minimale. A la première instance d'un score de qualité inférieur ou égal à truncQ, la séquence est tronquée.<br>
*   truncLen : définit à quelle longueur les séquences vont être tronquées. Les séquences plus courtes que la longueur sont éliminées.<br>
*   trimLeft : définit la longueur que l'on coupe du côté 5' des séquences. Celà permet d'enlever les amorces si ça n'a pas été fait préalablement.<br>
*   maxEE : définit le nombre maximum d '"erreurs attendues" autorisées dans une lecture. Ce filtre se base sur l'indice Q score. Plus on augmente le chiffre moins on est strict.<br>

D'autre paramètres peuvent également être modifiés, ils sont accessibles à la page d'aide de la fonction: ?filterAndTrim

<span style="color:darkblue">First, the function needs the unfiltered sequences (fnFs and FnRs) as well as the names of the objects of the filtered sequences (filtFs and filtRs). Several parameters can then be modified as we wish:

*   <span style="color:darkblue">truncQ: sets a minimum Q score. At the first instance of a quality score less than or equal to truncQ, the sequence is truncated.
*   <span style="color:darkblue">truncLen: sets the length at which the sequences will be truncated. Sequences shorter than the length are eliminated.
*   <span style="color:darkblue">trimLeft: sets the length that will be removed on the 5' side of the reads. This allows you to remove the primers if it has not been done beforehand.
*   <span style="color:darkblue">maxEE: sets the maximum number of “expected errors” allowed in a read. This filter is based on the Q index. The more the number is increased, the less strict we are. 

<span style="color:darkblue">Other settings can also be changed, they are accessible on the help page of the function : ?FilterAndTrim</span>


# ITS3_KYO2	GATGAAGAACGYAGYRAA = 18bp
# ITS4	TCCTCCGCTTATTGATATGC = 20b

```{r out, include=TRUE,cache=TRUE}
pourc <- cbind(out[,2]/out[,1])
plot(out)
plot(pourc)
pourc_disc <- cbind(out, pourc)
pourc_disc 
mean(out[,2])/mean(out[,1])
```



### Apprentissage des taux d'erreur / <span style="color:darkblue">Error Rates Learning</span>

Cet étape consiste à estimer le taux d'erreur de séquençage. Son but est de permettre de différencier les séquences mutantes et les séquences érronées.Le modèle d'erreur est calculé en alternant l'estimation du taux d'erreur et l'inférence de la composition de l'échantillon <br> 

<span style="color:darkblue"> This step consist in estimating the error rates due to sequencing. Its purpose is to differentiate between mutant sequences and false sequences. The error model is computed by alternating estimation of the error rates and inference of sample composition until they converge on a jointly consistent solution </span>

```{r err, include=TRUE,cache=TRUE}
errF <- learnErrors(filtFs)
errR <- learnErrors(filtRs)
```


#If nreads = 1e+06, convergence is after 5 rounds and Total reads used is 1013240. PlotErros output very very similar.

```{r viz_err, include=TRUE,cache=TRUE}
plotErrors(errF, nominalQ=TRUE)
plotErrors(errR, nominalQ=TRUE)
```

# The error rates for each possible transition (eg. A->C, A->G, …) are shown. 
# Points are the observed error rates for each consensus quality score. 
# The black line shows the estimated error rates after convergence. 
# The red line shows the error rates expected under the nominal definition of the Q-value (for Illumina technology). 

#### Dereplication ####

#combines all identical sequencing reads into into “unique sequences” with a corresponding “abundance”
#reduces computation time by eliminating redundant comparisons
derepFs <- derepFastq(filtFs, 
                      n = 1e+06) # no change obseved when n = 1e+07

derepRs <- derepFastq(filtRs, 
                      n = 1e+06)
# The consensus quality profile of a unique sequence is the average of the positional qualities from the dereplicated reads.

# Name the derep-class objects by the sample names
names(derepFs) <- sample.names
names(derepRs) <- sample.names

#### Sample Inference ####

# Infer the sequence variants in each sample
dadaFs <- dada(derepFs, 
               err = errF, 
               BAND_SIZE = 16, # Default is 16, based on 16S amplicon data that has lower indel rates than ITS. Only cost: run-time is longer. No differences observed when = 32
               KDIST_CUTOFF = 0.42, # Default is 0.42, based on 16S amplicon data. No differences observed when = .6
               pool=TRUE,
               multithread=TRUE)
dadaFs[[1]]

dadaRs <- dada(derepRs, 
               err=errR,
               pool=TRUE,
               multithread=TRUE)
dadaRs[[1]]

#save(dadaFs, file="data/dadaFs.rdata")
#save(dadaRs, file="data/dadaRs.rdata")

## Merging ####
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, 
                      minOverlap = 12, 
                      maxMismatch = 0, 
                      returnRejects = FALSE, 
                      propagateCol = character(0),
                      justConcatenate = FALSE, 
                      trimOverhang = FALSE)
# That way paired reads that did not exactly overlap were removed

# if returnRejects = TRUE
# pairs that that were rejected based on mismatches in the overlap region are retained BUT with accept = FALSE in table

# Inspect the merger data.frame from the first sample
# head(mergers[[1]])
# tail(mergers[[3]])
# max(mergers[[1]]$nmatch)
# min(mergers[[1]]$nmatch)

## Construct sequence table ####
## Exact sequence variants table
seqtab <- makeSequenceTable(mergers)
dim(seqtab)

## Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))

## Remove chimeras ####
seqtab.nochim <- removeBimeraDenovo(seqtab, 
                                    method = "pooled", # The samples in the sequence table are all pooled together for bimera identification.
                                    multithread = TRUE, verbose = TRUE) 

sum(seqtab.nochim)/sum(seqtab) # Percentage of the total sequence reads

# Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab.nochim)))

## save sequence table
#save(seqtab.nochim, file="data/seqtab.nochim.rdata")

## Exclude singletons and doubletons prior to taxonomic assignment
#seqtab.nochim.nosd = seqtab.nochim[,colSums(seqtab.nochim) > 200]

## Assign taxonomy ####
## Reference database at https://unite.ut.ee/repository.php
taxotab <- assignTaxonomy(seqtab.nochim,
                              refFasta = "reference_database/sh_general_release_dynamic_01.12.2017.fasta", 
                              minBoot = 50, #Default 50. The minimum bootstrap confidence for assigning a taxonomic level.
                              outputBootstraps = TRUE,
                              multithread = TRUE)

unique(unname(taxotab$tax[,7]))
View(taxotab)

## save taxonomy table
#save(taxtab, file="data/taxotab.01.05.rdata")

# NB1: dada2 does not throw away singleton reads. 
# However, it does not infer biological sequence variants that are only supported by a single read - singletons are assumed too difficult to differentiate from errors. 
# Hence no singletons in the output table of amplicon sequence variants.

# NB2: DADA2 consistently measures diversity across different filtering parameters and error rates. OTU methods do not.
# https://twitter.com/bejcal/status/771010634074820608

# NB3: The ASVs with no species assignment do not match the same species in over 50% of the bootstrap replicate kmer-based assignments 
# (see Wang et al. 2007 for more info on the naive Bayesian classifier method).


